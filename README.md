# ğŸ§  Machine Learning Projects â€“ Multiple Datasets

This repository contains implementations of various **Machine Learning algorithms** applied to multiple datasets during internship and project work at **Mahindra University**.  
The goal was to explore **supervised** and **unsupervised** learning techniques and apply them to real-world problems, including **Fashion Trend Analysis**.

---

## ğŸ“‚ Datasets Used
- ğŸŒ¸ **Iris Dataset** â€“ Flower classification  
- ğŸš— **Car Evaluation Dataset** â€“ Vehicle acceptability classification  
- ğŸŒ° **Dry Bean Dataset** â€“ Bean type identification  
- ğŸ›ï¸ **Mall Customer Dataset** â€“ Customer segmentation  
- ğŸ„ **Mushroom Dataset** â€“ Edible vs poisonous classification  
- ğŸ· **Wine Quality Dataset** â€“ Quality prediction  
- ğŸŒ± **Plant Communication Dataset** â€“ Plant trait analysis  
- ğŸ§¬ **Cancer Dataset (Denmark)** â€“ Cancer type classification  
- ğŸ§ª **Glass Classification Dataset** â€“ Glass type prediction  
- ğŸ‘— **Fashion-MNIST Dataset** â€“ Fashion trend analysis  

---

## âš™ï¸ Algorithms Implemented
### ğŸ”¹ Supervised Learning
- Decision Trees  
- Random Forests  
- Logistic Regression  
- Support Vector Machines (SVM)  
- k-Nearest Neighbors (k-NN)  
- NaÃ¯ve Bayes  
- Neural Networks  

### ğŸ”¹ Unsupervised Learning
- K-Means Clustering  
- Hierarchical Clustering  
- DBSCAN  

---

## ğŸ”„ Workflow
1. **Data Collection** â€“ Import datasets from CSV/UCI/Kaggle.  
2. **Data Preprocessing** â€“ Cleaning, normalization, encoding, handling missing values.  
3. **Exploratory Data Analysis (EDA)** â€“ Visualization, distribution checks, correlations.  
4. **Modeling** â€“ Apply supervised & unsupervised ML models.  
5. **Evaluation** â€“  
   - Classification: Accuracy, Precision, Recall, F1-score.  
   - Clustering: Silhouette Score.  
6. **Insights** â€“ Understanding patterns, classifications, and clusters for decision-making.  

---

## ğŸ“Š Key Results
- **Random Forest** â†’ Best performance in classification tasks (Accuracy ~90%+).  
- **Decision Tree** â†’ Good but less effective with overlapping classes.  
- **K-Means** â†’ Formed distinct clusters (Silhouette Score ~0.65).  
- **DBSCAN** â†’ Useful for detecting rare/niche items.  

---

## ğŸš€ Future Improvements
- Incorporate **brand, price, seasonal features** for fashion datasets.  
- Apply **deep learning (CNNs)** for image-based fashion analysis.  
- Develop **interactive dashboards** for visualization.  
- Use **feature selection techniques** to improve accuracy.  

---

## ğŸ› ï¸ Tools & Technologies
- **Python** (Jupyter Notebook)  
- **Libraries**: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, TensorFlow/Keras  

---

## ğŸ™ Acknowledgements
- **Mahindra University** â€“ Internship & guidance  
- **Faculty Mentors** â€“ Prof. Dr. Arun K. Pujari, Dr. Tauheed Ahmed, Dr. Shabnam Samima  
- **Dr. Motahar Reza (GITAM)** â€“ Provided opportunity  

---

## ğŸ“Œ How to Run
1. Clone the repo:  
   ```bash
   git clone https://github.com/your-username/ml-multiple-datasets.git
   cd ml-multiple-datasets



# ğŸŒ³ Decision Tree Learning Projects

Welcome to the repository for all my Decision Tree learning projects!  
This includes intuitive explanations, Python implementations, and story-based learning to understand how decision trees work, when they stop, and how they behave on real datasets.

---

## ğŸ“Œ Overview

This repository focuses on:
- Building and visualizing Decision Trees using Python and scikit-learn.
- Learning how Decision Trees work through simple **5-step logic** and **stories**.
- Applying the model to datasets like **Iris**.
- Understanding key concepts like Gini index, entropy, overfitting, stopping conditions, and tree depth.

---

## ğŸ§  What is a Decision Tree?

A **Decision Tree** is a supervised machine learning model used for classification or regression.  
It works by **splitting data** based on feature values and making decisions at each step until a **final output (leaf node)** is reached.

Think of it like playing **20 Questions** to guess the right answer. ğŸ¯

---

## âœ¨ Topics Covered

### âœ… 1. Decision Tree in 5 Steps
1. Select the best feature to split (based on Gini or Entropy)
2. Split the data into branches
3. Repeat for each subset
4. Stop when:
   - All samples are of the same class
   - No features left
   - Tree is deep enough
   - Not enough samples to split
   - No gain from further splits
5. Assign class labels at leaf nodes

---

### ğŸ“– 2. Story-Based Understanding

To make learning fun and memorable:
- **Tina the Tree** asks questions and stops when she's sure.
- **Captain Tree** follows smart stopping rules.
- **Detective Dot** classifies flowers based on petal and sepal clues.

---

### ğŸ“Š 3. Dataset Used â€“ Iris Dataset

- Features:
  - Petal Length & Width
  - Sepal Length & Width
- Classes:
  - Setosa
  - Versicolor
  - Virginica

---

### ğŸ§ª 4. Code Example (Iris Dataset)
```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

X, y = load_iris(return_X_y=True)
clf = DecisionTreeClassifier(max_depth=3)
clf.fit(X, y)

plot_tree(clf, filled=True)
plt.show()
